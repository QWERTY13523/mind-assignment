import os
import torch
import torch.nn.functional as F
import gradio as gr
import numpy as np
from PIL import Image
from torchvision import transforms
import torchvision.transforms.functional as TF

# --- å¯¼å…¥ä½ çš„æ¨¡å‹å®šä¹‰ ---
try:
    from main import BioCSTransNet, Config
except ImportError:
    print("Error: æ— æ³•æ‰¾åˆ° main.pyï¼Œè¯·ç¡®ä¿è¯¥æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
    exit()

# ==========================================
# 1. ç³»ç»Ÿé…ç½®ä¸æ¨¡å‹åŠ è½½
# ==========================================
WEIGHT_PATH = os.path.join(Config.SAVE_DIR, 'best_model_3090.pth')
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

print(f"æ­£åœ¨å¯åŠ¨ç³»ç»Ÿï¼Œä½¿ç”¨è®¾å¤‡: {DEVICE}...")

# å…¨å±€åŠ è½½æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼Œé¿å…æ¯æ¬¡é¢„æµ‹éƒ½é‡æ–°åŠ è½½ï¼‰
model = BioCSTransNet(num_classes=1).to(DEVICE)
if os.path.exists(WEIGHT_PATH):
    print(f"åŠ è½½æƒé‡: {WEIGHT_PATH}")
    checkpoint = torch.load(WEIGHT_PATH, map_location=DEVICE)
    # å¤„ç†å¯èƒ½çš„ module. å‰ç¼€
    state_dict = {k.replace("module.", ""): v for k, v in checkpoint.items()}
    model.load_state_dict(state_dict)
else:
    print(f"[è­¦å‘Š] æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ {WEIGHT_PATH}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹ï¼ˆä»…ä¾›æµ‹è¯•æµç¨‹ï¼‰")

model.eval()


# ==========================================
# 2. å›¾åƒå¤„ç†æ ¸å¿ƒé€»è¾‘
# ==========================================
def process_image(input_image, threshold, alpha):
    """
    input_image: Gradio ä¼ å…¥çš„å›¾ç‰‡ (numpy array)
    threshold: åˆ†å‰²é˜ˆå€¼ (0~1)
    alpha: å åŠ å›¾çš„é€æ˜åº¦ (0~1)
    """
    if input_image is None:
        return None, None

    # --- A. é¢„å¤„ç† ---
    # numpy -> PIL
    origin_pil = Image.fromarray(input_image).convert('RGB')
    w, h = origin_pil.size

    # Resize -> Tensor -> Normalize
    img_tensor = TF.resize(origin_pil, (Config.IMG_SIZE, Config.IMG_SIZE))
    img_tensor = TF.to_tensor(img_tensor)
    img_tensor = TF.normalize(img_tensor, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    img_tensor = img_tensor.unsqueeze(0).to(DEVICE)

    # --- B. æ¨¡å‹æ¨ç† ---
    with torch.no_grad():
        output = model(img_tensor)
        prob_map = torch.sigmoid(output)  # [1, 1, 352, 352]

    # --- C. åå¤„ç† ---
    # è¿˜åŸå›åŸå›¾å°ºå¯¸
    prob_map = F.interpolate(prob_map, size=(h, w), mode='bilinear', align_corners=True)
    prob_map = prob_map.squeeze().cpu().numpy()  # [H, W]

    # 1. ç”ŸæˆäºŒå€¼åŒ–æ©ç å›¾ (Black & White)
    mask_bin = (prob_map > threshold).astype(np.uint8) * 255
    mask_pil = Image.fromarray(mask_bin, mode='L')

    # 2. ç”Ÿæˆçº¢è‰²å åŠ å›¾ (Overlay) - è®©å±•ç¤ºæ›´é…·ç‚«
    # åˆ›å»ºä¸€ä¸ªçº¯çº¢è‰²çš„å›¾å±‚
    red_layer = Image.new("RGB", origin_pil.size, (255, 0, 0))
    # åˆ›å»º Mask å›¾å±‚ä½œä¸º alpha é€šé“
    mask_layer = Image.fromarray((prob_map * 255 * alpha).astype(np.uint8), mode='L')
    # å°†çº¢å±‚å åŠ åˆ°åŸå›¾
    overlay_pil = Image.composite(red_layer, origin_pil, mask_layer)

    return mask_pil, overlay_pil


# ==========================================
# 3. æœç´¢ç¤ºä¾‹å›¾ç‰‡ (ç”¨äºç‚¹å‡»æµ‹è¯•)
# ==========================================
examples = []
if os.path.exists(Config.VAL_IMG_DIR):
    # æ‰¾å‰3å¼ å›¾ç‰‡ä½œä¸ºç¤ºä¾‹
    imgs = [os.path.join(Config.VAL_IMG_DIR, x) for x in os.listdir(Config.VAL_IMG_DIR) if x.endswith('.jpg')]
    examples = sorted(imgs)[:4]

# ==========================================
# 4. æ„å»º Gradio ç•Œé¢
# ==========================================

with gr.Blocks(title="Bio-CSTransNet Demo") as demo:
    gr.Markdown(
        """
        # ğŸ¦ Bio-CSTransNet: ä¼ªè£…ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ
        åŸºäº **Swin Transformer** ä¸ **ç±»è„‘ä¸­å¿ƒæ‹®æŠ—æœºåˆ¶** çš„é«˜ç²¾åº¦ä¼ªè£…ç›®æ ‡æ£€æµ‹ã€‚
        """
    )

    with gr.Row():
        # --- å·¦ä¾§ï¼šæ§åˆ¶åŒº ---
        with gr.Column(scale=1):
            input_img = gr.Image(label="ä¸Šä¼ å›¾ç‰‡ (Input)", type="numpy")

            with gr.Accordion("âš™ï¸ å‚æ•°è°ƒèŠ‚ (Advanced Settings)", open=True):
                thresh_slider = gr.Slider(minimum=0.0, maximum=1.0, value=0.5, label="åˆ¤å®šé˜ˆå€¼ (Threshold)")
                alpha_slider = gr.Slider(minimum=0.0, maximum=1.0, value=0.6, label="å åŠ é€æ˜åº¦ (Alpha)")

            run_btn = gr.Button("ğŸš€ å¼€å§‹æ£€æµ‹ (Detect)", variant="primary")

            # ç¤ºä¾‹åŒº
            if examples:
                gr.Examples(examples=examples, inputs=input_img, label="ç‚¹å‡»ç¤ºä¾‹å¿«é€Ÿæµ‹è¯•")

        # --- å³ä¾§ï¼šç»“æœåŒº ---
        with gr.Column(scale=2):
            with gr.Tab("å¯è§†åŒ–ç»“æœ"):
                # ä½¿ç”¨ Gallery å¯ä»¥æ”¯æŒå·¦å³æ»‘åŠ¨æŸ¥çœ‹ï¼Œä¹Ÿå¯ä»¥ç›´æ¥å¹¶æ’æ˜¾ç¤º
                # è¿™é‡Œæˆ‘ä»¬ç”¨å¹¶æ’æ˜¾ç¤ºæ›´ç›´è§‚
                with gr.Row():
                    output_mask = gr.Image(label="é¢„æµ‹æ©ç  (Binary Mask)", type="pil")
                    output_overlay = gr.Image(label="èåˆå¯è§†åŒ– (Overlay)", type="pil")

    # ç»‘å®šäº‹ä»¶
    # 1. ç‚¹å‡»æŒ‰é’®è§¦å‘
    run_btn.click(
        fn=process_image,
        inputs=[input_img, thresh_slider, alpha_slider],
        outputs=[output_mask, output_overlay]
    )
    # 2. æ»‘åŠ¨å‚æ•°æ—¶è‡ªåŠ¨è§¦å‘ (å¯é€‰ï¼Œä¸ºäº†æµç•…ä½“éªŒå»ºè®®å…³é—­ï¼Œæˆ–è€…åªç»‘å®š alpha)
    # thresh_slider.change(fn=process_image, inputs=[input_img, thresh_slider, alpha_slider], outputs=[output_mask, output_overlay])

# ==========================================
# 5. å¯åŠ¨æœåŠ¡
# ==========================================
if __name__ == "__main__":
    print("ç³»ç»Ÿå¯åŠ¨æˆåŠŸï¼è¯·åœ¨æµè§ˆå™¨è®¿é—®ä¸‹é¢çš„é“¾æ¥...")
    # share=True ä¼šç”Ÿæˆä¸€ä¸ªå…¬ç½‘é“¾æ¥ï¼Œæ–¹ä¾¿ä½ å‘ç»™åˆ«äººçœ‹
    demo.launch(share=True, server_name="0.0.0.0", server_port=7860)