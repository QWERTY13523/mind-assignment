import os

# è®¾ç½®å›½å†…é•œåƒ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
import timm

# ä»Ž main.py å¯¼å…¥é…ç½®å’Œæ•°æ®é›†ï¼Œç¡®ä¿"æŽ§åˆ¶å˜é‡æ³•"ï¼Œé™¤äº†æ¨¡åž‹ç»“æž„å¤–å…¶ä»–å®Œå…¨ä¸€è‡´
try:
    from main import Config, CODDataset, DecoderBlock
except ImportError:
    print("Error: æ— æ³•å¯¼å…¥ main.pyï¼Œè¯·ç¡®ä¿è¯¥æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹ã€‚")
    exit()


# ==========================================
# 1. å®šä¹‰ Baseline æ¨¡åž‹ (æ—  CS æ¨¡å—)
# ==========================================
class BioCSTransNet_Baseline(nn.Module):
    """
    [Ablation Version]
    ç»“æž„: Swin-Base -> (ç›´è¿ž) -> Decoder
    ä½œç”¨: è¯æ˜Ž CS æ¨¡å—çš„æœ‰æ•ˆæ€§
    """

    def __init__(self, num_classes=1, backbone_name=Config.BACKBONE):
        super(BioCSTransNet_Baseline, self).__init__()
        print(f"ðŸ”¥ [Ablation] Loading Baseline Model (WITHOUT CS Module)...")

        # 1. åŠ è½½éª¨å¹² (ä¿æŒä¸€è‡´)
        self.backbone = timm.create_model(
            backbone_name,
            pretrained=True,
            features_only=True,
            img_size=Config.IMG_SIZE
        )
        dims = self.backbone.feature_info.channels()

        # --- å…³é”®ä¿®æ”¹ç‚¹ 1: ç§»é™¤äº† CS æ¨¡å—çš„åˆå§‹åŒ– ---
        # self.cs_block4 = CenterSurroundModule(dims[3])
        # self.cs_block3 = CenterSurroundModule(dims[2])

        # 2. è§£ç å™¨ (ä¿æŒä¸€è‡´)
        self.decoder4 = DecoderBlock(dims[3], dims[2], 512)
        self.decoder3 = DecoderBlock(512, dims[1], 256)
        self.decoder2 = DecoderBlock(256, dims[0], 128)

        self.final_conv = nn.Conv2d(128, num_classes, 1)

    def forward(self, x):
        features = self.backbone(x)
        c1, c2, c3, c4 = features[0], features[1], features[2], features[3]

        # ç»´åº¦è°ƒæ•´ (Swin çš„ NHWC -> NCHW) å¿…é¡»ä¿ç•™
        if c4.size(-1) == self.backbone.feature_info.channels()[-1]:
            c1 = c1.permute(0, 3, 1, 2).contiguous()
            c2 = c2.permute(0, 3, 1, 2).contiguous()
            c3 = c3.permute(0, 3, 1, 2).contiguous()
            c4 = c4.permute(0, 3, 1, 2).contiguous()

        # --- å…³é”®ä¿®æ”¹ç‚¹ 2: ç§»é™¤äº† CS æ¨¡å—çš„å¤„ç† ---
        # c4_enhanced = self.cs_block4(c4)
        # c3_enhanced = self.cs_block3(c3)

        # ç›´æŽ¥å°†éª¨å¹²ç‰¹å¾ä¼ ç»™è§£ç å™¨
        # è¿™é‡Œçš„ç‰¹å¾æ˜¯"åŽŸæ±åŽŸå‘³"çš„ Transformer ç‰¹å¾ï¼Œæ²¡æœ‰ç»è¿‡ä»¿ç”Ÿå¢žå¼º
        d4 = self.decoder4(c4, c3)
        d3 = self.decoder3(d4, c2)
        d2 = self.decoder2(d3, c1)

        logits = self.final_conv(d2)
        out = F.interpolate(logits, scale_factor=4, mode='bilinear', align_corners=True)
        return out


# ==========================================
# 2. è®­ç»ƒè¾…åŠ©å‡½æ•°
# ==========================================
def train_one_epoch(model, loader, optimizer, criterion, device, epoch):
    model.train()
    epoch_loss = 0
    print(f"\nEpoch [{epoch + 1}/{Config.EPOCHS}] Training (Baseline)...")
    for step, (images, masks) in enumerate(loader):
        images, masks = images.to(device), masks.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
        if step % 50 == 0:
            print(f"  Step [{step}/{len(loader)}] Loss: {loss.item():.4f}")
    return epoch_loss / len(loader)


def validate(model, loader, device):
    model.eval()
    total_iou = 0
    with torch.no_grad():
        for images, masks in loader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            pred = (torch.sigmoid(outputs) > 0.5).float()
            inter = (pred * masks).sum()
            union = pred.sum() + masks.sum() - inter
            iou = (inter + 1e-6) / (union + 1e-6)
            total_iou += iou.item()
    return total_iou / len(loader)


# ==========================================
# 3. ä¸»ç¨‹åº
# ==========================================
if __name__ == '__main__':
    print(f"Starting Ablation Study on {Config.device}...")

    # 1. è®¾ç½®ä¿å­˜è·¯å¾„ (ä¸Žä¸»å®žéªŒåŒºåˆ†å¼€)
    ABLATION_SAVE_DIR = './checkpoints_ablation'
    if not os.path.exists(ABLATION_SAVE_DIR):
        os.makedirs(ABLATION_SAVE_DIR)

    # 2. æ•°æ®åŠ è½½ (å¤ç”¨ Config)
    train_dataset = CODDataset(Config.TRAIN_IMG_DIR, Config.TRAIN_MASK_DIR, is_train=True)
    val_dataset = CODDataset(Config.VAL_IMG_DIR, Config.VAL_MASK_DIR, is_train=False)

    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=Config.NUM_WORKERS)
    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=Config.NUM_WORKERS)

    # 3. åˆå§‹åŒ– Baseline æ¨¡åž‹
    model = BioCSTransNet_Baseline(num_classes=1).to(Config.device)

    # 4. ä¼˜åŒ–å™¨ä¸Ž Loss (ä¿æŒä¸Žä¸»å®žéªŒå®Œå…¨ä¸€è‡´)
    pos_weight = torch.tensor([10.0]).to(Config.device)
    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
    optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE, weight_decay=Config.WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.EPOCHS, eta_min=1e-6)

    # 5. å¼€å§‹è®­ç»ƒ
    best_iou = 0.0
    for epoch in range(Config.EPOCHS):
        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, Config.device, epoch)
        val_iou = validate(model, val_loader, Config.device)
        scheduler.step()

        print(f"Baseline Epoch [{epoch + 1}/{Config.EPOCHS}] Loss: {train_loss:.4f} | Val IoU: {val_iou:.4f}")

        if val_iou > best_iou:
            best_iou = val_iou
            save_path = os.path.join(ABLATION_SAVE_DIR, 'best_model_baseline.pth')
            torch.save(model.state_dict(), save_path)
            print(f"  >>> Best Baseline Saved! (IoU: {best_iou:.4f})")

    print("\nâœ… Ablation Study Finished.")